가끔 Unicode 처리가 짜증난다고, 혹은 어렵다고 하는 사람들이 있는데 잘 이해가 안된다. JPEG, PNG 같은 이미지 포맷으로 저장된 파일을 열 때 디코드해서 메모리에 비트맵을 올리고, 다시 저장할 때는 인코딩한다. 동영상도 마찬가지다. 사운드도 그렇다. 쿼리 스트링을 바이트열로 받아서 파싱해서 multiple hash로 다루고, 다시 쿼리 스트링으로 만들어낸다. 숫자 입력을 받을 때는 ASCII로 인코딩된 10진수를 바이트열로 받고, `atoi()`해서 메모리에 올린 뒤에, 출력을 할 때는 다시 `itoa()`를 통해 바이트열로 바꿔서 보낸다.

마찬가지로 문자열 입력을 받을 때는 어떤 인코딩(예를 들어 UTF-8, EUC-KR 등)으로 가공된 바이트열을 받아서 Unicode로 디코드한다. 쓸 때는 상대방이 알아들을 수 있는 인코딩으로 다시 인코드한다. 입력받을 때는 디코드, 출력할 때는 인코드. 열 때는 디코드, 저장할 때는 인코드. 어렵나?

외부 세계의 표현(representation)과 내부 표현이 다를 때는 인코딩/디코딩이 필요하다. 프로그래밍 조금 해봤으면 누구나 아는 것 아닌가? 왜 다른 비슷한 패턴은 잘들 하면서 Unicode 문자열 처리에 대해서만 그렇게 짜증나는 일이라고 여길까?

예전에 [Unicode 이해의 다양한 단계들][1]에 대해 글을 쓴 적 있는데, Unicode 인코딩/디코딩에서 헤매는 사람들은 저 글 기준으로 3번째 수준(UTF-8을 쓰니 Unicode 완비되었다고 생각하는 사람) 혹은 4번째 수준(세상에는 여러 종류의 인코딩이 존재하고 있다는 것을 아는 사람. iconv도 사용할 줄 안다)에 머물고 있지 않을까 짐작해본다.

[1]: http://blog.dahlia.kr/post/1268041887
